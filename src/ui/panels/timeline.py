from PyQt6.QtWidgets import QFrame, QVBoxLayout, QLabel, QHBoxLayout, QPushButton, QWidget, QMessageBox
from PyQt6.QtCore import Qt
from src.ui.timeline.timeline_widget import TimelineWidget


class Timeline(QFrame):
    def __init__(self):
        super().__init__()
        self.setObjectName("panel")
        layout = QVBoxLayout(self)
        layout.setContentsMargins(0, 0, 0, 0)
        
        # Worker references to prevent garbage collection
        self._transcription_worker = None
        self._tts_worker = None
        self._progress_dialog = None
        
        # Header
        header_container = QWidget()
        header_layout = QHBoxLayout(header_container)
        header_layout.setContentsMargins(0, 0, 0, 0)
        
        title = QLabel("Timeline")
        title.setObjectName("panel_title")
        header_layout.addWidget(title)
        
        # AI Tools Section
        ai_label = QLabel("AI Tools:")
        ai_label.setStyleSheet("color: #8b9dc3; margin-left: 10px;")
        header_layout.addWidget(ai_label)
        
        # Auto Sub Button (combines Generate + Remove subtitle features)
        self.caption_btn = QPushButton("üìù Auto Sub")
        self.caption_btn.setObjectName("primary")
        self.caption_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        self.caption_btn.clicked.connect(self.open_caption_dialog)
        header_layout.addWidget(self.caption_btn)
        
        # TTS Button
        self.tts_btn = QPushButton("üé§ Text to Speech")
        self.tts_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        self.tts_btn.setStyleSheet("""
            QPushButton {
                background-color: #2C2C2C;
                border: 1px solid #3E3E3E;
            }
            QPushButton:hover {
                background-color: #3E3E3E;
                border-color: #505050;
            }
        """)
        self.tts_btn.clicked.connect(self.open_tts_dialog)
        header_layout.addWidget(self.tts_btn)
        
        header_layout.addStretch()
        
        layout.addWidget(header_container)
        
        # Timeline Widget
        self.timeline_widget = TimelineWidget()
        layout.addWidget(self.timeline_widget)

    def open_caption_dialog(self):
        """Open dialog to configure and run auto sub (transcribe, translate, or remove)."""
        from src.ui.dialogs.ai_dialogs import CaptionDialog
        
        # Check if there's a clip
        track = self.timeline_widget.main_track
        if not track.clips:
            QMessageBox.warning(self, "Auto Sub", "Kh√¥ng c√≥ video trong timeline.\nVui l√≤ng th√™m video tr∆∞·ªõc.")
            return
        
        dialog = CaptionDialog(self)
        if dialog.exec():
            mode = dialog.get_mode()
            
            if mode == "remove":
                # Handle Remove Sub mode
                settings = dialog.get_remove_settings()
                self.start_subtitle_removal(settings)
            else:
                # Handle Transcribe or Translate mode
                language = dialog.get_language()
                translate_to = dialog.get_translate_to()
                self.start_transcription(language, translate_to)
    
    def start_transcription(self, language=None, translate_to=None):
        """Start transcription with progress dialog."""
        from src.ui.dialogs.ai_progress import AIProgressDialog, TranscriptionWorker
        
        print(f"[DEBUG] start_transcription called with language={language}, translate_to={translate_to}")
        
        track = self.timeline_widget.main_track
        if not track.clips:
            return
            
        clip = track.clips[0]
        
        # Store for retry with fallback
        self._current_clip = clip
        self._current_translate_to = translate_to
        self._current_language = language
        
        # Show progress dialog
        if translate_to:
            title = "üåê ƒêang d·ªãch..."
            msg = f"Transcribe v√† d·ªãch sang {translate_to.upper()}"
        else:
            title = "üéØ Auto Caption"
            msg = "ƒêang transcribe audio..."
            
        self._progress_dialog = AIProgressDialog(self, title=title, message=msg)
        self._progress_dialog.set_status("‚è≥ ƒêang t·∫£i model AI...")
        
        # Create worker thread
        print(f"[DEBUG] Creating TranscriptionWorker with file={clip.asset_id}, translate_to={translate_to}")
        self._transcription_worker = TranscriptionWorker(clip.asset_id, language, translate_to)
        self._transcription_worker.progress.connect(self._on_transcription_progress)
        self._transcription_worker.finished.connect(self._on_transcription_finished)
        self._transcription_worker.error.connect(self._on_transcription_error)
        self._transcription_worker.rate_limit.connect(self._on_rate_limit)
        self._transcription_worker.start()
        
        self._progress_dialog.exec()
    
    def _on_transcription_progress(self, status: str):
        if self._progress_dialog:
            self._progress_dialog.set_status(status)
    
    def _on_transcription_finished(self, segments: list):
        if self._progress_dialog:
            self._progress_dialog.set_complete(True)
            self._progress_dialog.set_status(f"‚úÖ Ho√†n th√†nh! T·∫°o ƒë∆∞·ª£c {len(segments)} ƒëo·∫°n subtitle.")
            
        if segments:
            track = self.timeline_widget.main_track
            if track.clips:
                clip = track.clips[0]
                self.timeline_widget.add_subtitle_track(segments, start_offset=clip.start_time)
            
            # Pass subtitles to Player for live display
            self._update_player_subtitles()
            
            # Show success message
            QMessageBox.information(
                self, 
                "Auto Caption", 
                f"‚úÖ ƒê√£ t·∫°o {len(segments)} ƒëo·∫°n subtitle!\n\n"
                f"üìç Subtitles s·∫Ω hi·ªÉn th·ªã tr√™n video khi play\n"
                f"üí° Click v√†o ƒëo·∫°n subtitle ƒë·ªÉ xem n·ªôi dung trong Inspector"
            )
        else:
            QMessageBox.warning(self, "Auto Caption", "Kh√¥ng t√¨m th·∫•y l·ªùi n√≥i trong video.")
        
        if self._progress_dialog:
            self._progress_dialog.accept()
    
    def _update_player_subtitles(self):
        """Pass subtitle clips to Player for live display."""
        try:
            # Find parent edit_page to access player
            parent = self.parent()
            while parent:
                if hasattr(parent, 'player'):
                    # Get subtitle clips from timeline
                    for track in self.timeline_widget.tracks:
                        if track.name == "Subtitles":
                            parent.player.set_subtitles(track.clips)
                            print(f"Passed {len(track.clips)} subtitles to Player")
                            break
                    break
                parent = parent.parent()
        except Exception as e:
            print(f"Error updating player subtitles: {e}")
    
    def _on_transcription_error(self, error: str):
        if self._progress_dialog:
            self._progress_dialog.set_complete(False)
            self._progress_dialog.set_status(f"‚ùå L·ªói: {error}")
        
        QMessageBox.critical(self, "Auto Caption Error", f"L·ªói khi transcribe:\n{error}")
        
        if self._progress_dialog:
            self._progress_dialog.accept()
    
    def _on_rate_limit(self, provider: str):
        """Handle rate limit error - ask user if they want to fallback to Google Translate."""
        if self._progress_dialog:
            self._progress_dialog.hide()
        
        reply = QMessageBox.question(
            self,
            "‚ö†Ô∏è API Rate Limit",
            f"‚ùå {provider} ƒë√£ h·∫øt quota mi·ªÖn ph√≠ h√¥m nay!\n\n"
            f"B·∫°n c√≥ mu·ªën d√πng Google Translate (mi·ªÖn ph√≠, kh√¥ng gi·ªõi h·∫°n) ƒë·ªÉ ti·∫øp t·ª•c?\n\n"
            f"‚Ä¢ Google Translate: Nhanh, mi·ªÖn ph√≠, ch·∫•t l∆∞·ª£ng t·ªët\n"
            f"‚Ä¢ Gemini Pro: Ch·ªù ƒë·∫øn ng√†y mai ƒë·ªÉ reset quota",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.Yes
        )
        
        if reply == QMessageBox.StandardButton.Yes:
            # Switch to Google Translate and retry
            from src.core.ai.translation import translation_service
            translation_service.set_provider("google")
            
            # Close old dialog
            if self._progress_dialog:
                self._progress_dialog.accept()
            
            # Restart with Google Translate
            print("üîÑ Retrying with Google Translate...")
            self.start_transcription(self._current_language, self._current_translate_to)
        else:
            # User cancelled
            if self._progress_dialog:
                self._progress_dialog.set_complete(False)
                self._progress_dialog.set_status("‚ùå ƒê√£ h·ªßy do rate limit")
                self._progress_dialog.accept()
            
            QMessageBox.information(
                self,
                "Th√¥ng b√°o",
                "Vui l√≤ng th·ª≠ l·∫°i sau ho·∫∑c d√πng Google Translate trong c√†i ƒë·∫∑t."
            )

    def open_tts_dialog(self):
        """Open TTS dialog with voice selection."""
        from src.ui.dialogs.ai_dialogs import TTSDialog
        
        dialog = TTSDialog(self)
        if dialog.exec():
            text = dialog.get_text()
            voice = dialog.get_voice()
            
            if text:
                self.start_tts(text, voice)
    
    def start_tts(self, text: str, voice: str):
        """Start TTS generation with progress dialog."""
        from src.ui.dialogs.ai_progress import AIProgressDialog, TTSWorker
        import os
        import tempfile
        import time
        
        # Generate output path
        temp_dir = tempfile.gettempdir()
        output_path = os.path.join(temp_dir, f"tts_{int(time.time())}.mp3")
        
        # Show progress dialog
        self._progress_dialog = AIProgressDialog(
            self, 
            title="üé§ Text to Speech",
            message="ƒêang t·∫°o gi·ªçng n√≥i..."
        )
        self._progress_dialog.set_status(f"üîä Voice: {voice}")
        
        # Create worker thread
        self._tts_worker = TTSWorker(text, output_path, voice)
        self._tts_worker.progress.connect(self._on_tts_progress)
        self._tts_worker.finished.connect(lambda path, dur: self._on_tts_finished(path, dur, text))
        self._tts_worker.error.connect(self._on_tts_error)
        self._tts_worker.start()
        
        self._progress_dialog.exec()
    
    def _on_tts_progress(self, status: str):
        if self._progress_dialog:
            self._progress_dialog.set_status(status)
    
    def _on_tts_finished(self, output_path: str, duration: float, text: str):
        from src.core.timeline.clip import Clip
        from src.core.timeline.track import Track
        
        if self._progress_dialog:
            self._progress_dialog.set_complete(True)
            self._progress_dialog.set_status(f"‚úÖ Ho√†n th√†nh! Duration: {duration:.1f}s")
        
        # Find or create AI Voiceover track
        audio_track = None
        for track in self.timeline_widget.tracks:
            if track.name == "AI Voiceover":
                audio_track = track
                break
        
        if not audio_track:
            audio_track = Track("AI Voiceover", is_audio=True)
            self.timeline_widget.tracks.append(audio_track)
        
        # Create Clip
        clip = Clip(
            asset_id=output_path,
            name=f"üé§ {text[:20]}..." if len(text) > 20 else f"üé§ {text}",
            duration=duration,
            waveform_path=None
        )
        audio_track.clips.append(clip)
        
        self.timeline_widget.refresh_tracks()
        
        # Show success message
        QMessageBox.information(
            self, 
            "Text to Speech", 
            f"‚úÖ ƒê√£ t·∫°o audio th√†nh c√¥ng!\n\n"
            f"‚è± Duration: {duration:.1f} gi√¢y\n"
            f"üìç Xem k·∫øt qu·∫£: Track 'AI Voiceover' trong Timeline\n"
            f"üîä Click Play ƒë·ªÉ nghe audio"
        )
        
        if self._progress_dialog:
            self._progress_dialog.accept()
    
    def _on_tts_error(self, error: str):
        if self._progress_dialog:
            self._progress_dialog.set_complete(False)
            self._progress_dialog.set_status(f"‚ùå L·ªói: {error}")
        
        QMessageBox.critical(self, "TTS Error", f"L·ªói khi t·∫°o gi·ªçng n√≥i:\n{error}")
        
        if self._progress_dialog:
            self._progress_dialog.accept()

    def open_subtitle_removal_dialog(self):
        """Open dialog to configure subtitle removal."""
        from src.ui.dialogs.subtitle_removal_dialog import SubtitleRemovalDialog
        
        # Check if there's a clip
        track = self.timeline_widget.main_track
        if not track.clips:
            QMessageBox.warning(self, "Remove Subtitles", "Kh√¥ng c√≥ video trong timeline.\nVui l√≤ng th√™m video tr∆∞·ªõc.")
            return
        
        dialog = SubtitleRemovalDialog(self)
        if dialog.exec():
            settings = dialog.get_settings()
            if settings:
                self.start_subtitle_removal(settings)
    
    def start_subtitle_removal(self, settings: dict):
        """Start subtitle removal with progress dialog."""
        from src.ui.dialogs.ai_progress import AIProgressDialog
        from PyQt6.QtCore import QThread, pyqtSignal
        import os
        import time
        
        track = self.timeline_widget.main_track
        if not track.clips:
            return
        
        clip = track.clips[0]
        input_path = clip.asset_id
        
        # Generate output path
        base_name = os.path.splitext(os.path.basename(input_path))[0]
        output_dir = os.path.dirname(input_path)
        output_path = os.path.join(output_dir, f"{base_name}_no_sub.mp4")
        
        # Store for use in callbacks
        self._sub_removal_output = output_path
        self._sub_removal_settings = settings
        
        # Show progress dialog
        self._progress_dialog = AIProgressDialog(
            self, 
            title="üóëÔ∏è Removing Subtitles",
            message="ƒêang xo√° subtitle t·ª´ video..."
        )
        self._progress_dialog.set_status("‚è≥ ƒêang x·ª≠ l√Ω...")
        
        # Create worker thread
        class SubtitleRemovalWorker(QThread):
            progress = pyqtSignal(str)
            finished = pyqtSignal(str)  # output path
            error = pyqtSignal(str)
            
            def __init__(self, input_path, output_path, settings):
                super().__init__()
                self.input_path = input_path
                self.output_path = output_path
                self.settings = settings
            
            def run(self):
                try:
                    from src.core.ai.subtitle_remover import subtitle_remover_service
                    
                    algorithm = self.settings.get("algorithm", "blur")
                    bottom_percent = self.settings.get("bottom_percent", 0.15)
                    
                    if algorithm == "inpaint":
                        # Use slow but high-quality OpenCV inpaint
                        self.progress.emit("üê¢ AI Inpainting (s·∫Ω m·∫•t 30+ ph√∫t)...")
                        success = subtitle_remover_service.process_video(
                            self.input_path,
                            self.output_path,
                            progress_callback=lambda c, t: self.progress.emit(f"‚è≥ Frame {c}/{t}"),
                            region=None  # Auto-detect
                        )
                    else:
                        # Use fast FFmpeg methods
                        self.progress.emit(f"üöÄ Processing with FFmpeg ({algorithm})...")
                        success = subtitle_remover_service.remove_subtitles_ffmpeg(
                            self.input_path,
                            self.output_path,
                            bottom_percent=bottom_percent,
                            method=algorithm  # blur, black, or crop
                        )
                    
                    if success:
                        self.finished.emit(self.output_path)
                    else:
                        self.error.emit("Failed to process video")
                        
                except Exception as e:
                    self.error.emit(str(e))
        
        self._sub_removal_worker = SubtitleRemovalWorker(input_path, output_path, settings)
        self._sub_removal_worker.progress.connect(self._on_sub_removal_progress)
        self._sub_removal_worker.finished.connect(self._on_sub_removal_finished)
        self._sub_removal_worker.error.connect(self._on_sub_removal_error)
        self._sub_removal_worker.start()
        
        self._progress_dialog.exec()
    
    def _on_sub_removal_progress(self, status: str):
        if self._progress_dialog:
            self._progress_dialog.set_status(status)
    
    def _on_sub_removal_finished(self, output_path: str):
        if self._progress_dialog:
            self._progress_dialog.set_complete(True)
            self._progress_dialog.set_status("‚úÖ Ho√†n th√†nh!")
        
        QMessageBox.information(
            self, 
            "Remove Subtitles", 
            f"‚úÖ ƒê√£ xo√° subtitle th√†nh c√¥ng!\n\n"
            f"üìÅ File m·ªõi: {os.path.basename(output_path)}\n"
            f"üìç Folder: {os.path.dirname(output_path)}"
        )
        
        if self._progress_dialog:
            self._progress_dialog.accept()
    
    def _on_sub_removal_error(self, error: str):
        if self._progress_dialog:
            self._progress_dialog.set_complete(False)
            self._progress_dialog.set_status(f"‚ùå L·ªói: {error}")
        
        QMessageBox.critical(self, "Remove Subtitles Error", f"L·ªói:\n{error}")
        
        if self._progress_dialog:
            self._progress_dialog.accept()
